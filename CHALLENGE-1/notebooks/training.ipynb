{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a29a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Author: Annam.ai IIT Ropar\n",
    "Team Name: Ice 'N' Dagger\n",
    "Team Members: Barun Saha, Bibaswan Das\n",
    "Leaderboard Rank: 70 \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the notebook used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d4cab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# training.ipynb\n",
    "!pip install -q torch torchvision timm pandas scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbdb35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "from preprocessing import SoilDataset, train_transform, test_transform\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"swin_base_patch4_window7_224\"\n",
    "TRAIN_DIR = \"/kaggle/input/soil-classification/soil_classification-2025/train\"\n",
    "BEST_MODEL_PATH = \"best_model.pth\"\n",
    "\n",
    "# Load encoded data\n",
    "df = pd.read_csv(\"encoded_train.csv\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "train_dataset = SoilDataset(train_df, TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = SoilDataset(val_df, TRAIN_DIR, transform=test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Model\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=len(label_encoder.classes_))\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Loss and optimizer\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_df['label']), y=train_df['label'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "best_min_f1 = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1_scores = f1_score(val_labels, val_preds, average=None, labels=list(range(len(label_encoder.classes_))))\n",
    "    min_f1 = f1_scores.min()\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Acc: {train_acc:.4f}, Min F1 Score: {min_f1:.4f}\")\n",
    "\n",
    "    if min_f1 > best_min_f1:\n",
    "        best_min_f1 = min_f1\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"Saved new best model with min F1: {best_min_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
